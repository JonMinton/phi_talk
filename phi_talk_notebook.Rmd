---
title: "The Infer Package and Bayes Factors"
output: html_notebook
author: "Jon Minton"
---

# Introduction 

This document will introduce a couple of concepts, and one R package, for performing statistical inference tests in R.

1. The There-is-only-one-test framework, and the R package infer
2. Bayes Factors, as distinct from Neyman-Pearson Hypothesis Testing frameoworks

# Proposed structure

* TIOOT/Infer
    * There-is-only-one-test : background
        * Allen Downey - a computer scientist's take on statistical inference
            * 2011 - [There is only one test](http://allendowney.blogspot.com/2011/05/there-is-only-one-test.html)
            * 2016 - [There is still only one test](http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html)
            * ![Key Figure](figures/dcq7d5hs_237c9bcfngs_b.png)
        * Null & Alternative Hypothesis
            * Null $H_0$: The (boring) world in which the proposed relationship between predictor and response variables is *false*
            * Alternative $H_A$: The (interesting) world in which the proposed relationship between predictor and response is *true*
        * P-values 
            * > P-values are a measure of conflict between data and a hypothesis, and are certainly not direct expressions of a probability of hypotheses.
                * [Communicating Uncertainty about facts, numbers, and science](https://royalsocietypublishing.org/doi/pdf/10.1098/rsos.181870)
            * P-values are usually *indirect* strategies for investigating support for $H_A$, through quantifying *magnitude* and *direction* of conflict between data and $H_0$
                * *Direction of conflict*: One-tailed cf two-tailed tests
                * *Magnitude of conflict*: Probability of observing values of effect $\delta^{*}$ as or more extreme under $H_0$.
            * Neyman-Pearson Approach
                * Also prespecify $\alpha$: The magnitude of conflict between data and Null hypothesis, in expected direction, required to 'reject the Null'
                * Typical $\alpha$ values: 0.05, 0.01
                    * CERN: 'Five Sigma' (almost zero)
                * [The Sizeless Stare](https://www.amazon.co.uk/Cult-Statistical-Significance-Economics-Cognition/dp/0472050079)
            * Permutation approaches
                * A generic, computationally intensive, approach to producing a distribution of expected effect sizes under the Null
                * Key intuition:
                    * $H_A$ says $X$ predicts/causes $Y$
                    * Put another way:  Values of $X$ are *informative* as to values of $Y$
                    * Say $X$ is categorical, and can either be $A$ or $B$
                    * The data $D$ is a series of values of $Y$, with *labels* attached: the corresponding values of $X$
                    * Another way of expressing $H_A$ and $H_0$:
                        * $H_A$: These labels *matter* (Are informative of $Y$)
                        * $H_0$: These labels *don't matter* (Are not informative of $Y$)
                    * A corollary of $H_0$: If the labels don't matter, there's no harm (information lost) by reallocating them to $Y$ values at random
                    * Random reallocation: Permutation
                    * Repeat many times to estimate the Null distribution 
    * [Infer package](https://github.com/tidymodels/infer)
        * ![Key Figure](https://raw.githubusercontent.com/tidymodels/infer/master/figs/ht-diagram.png)
        * Verbs
            * `specify`
            * `hypothesize`
            * `generate`
            * `calculate`
    * DataCamp courses [(Learner beware)](https://www.buzzfeednews.com/article/daveyalba/datacamp-sexual-harassment-metoo-tech-startup)
        * [Foundations of Inference](https://www.datacamp.com/courses/foundations-of-inference)
        * [Inference for Linear Regression](https://www.datacamp.com/courses/inference-for-linear-regression)
        * [Inference for Numeric Data](https://www.datacamp.com/courses/inference-for-numerical-data)
        * [Inference for Categorical Data](https://www.datacamp.com/courses/inference-for-categorical-data)
    * [Avoiding Datacamp](https://bookdown.org/cteplovs/ismaykim/ismaykim.pdf)

# Examples of infer

```{r}
pacman::p_load(tidyverse, infer)

```

# Initial example: mtcars

* [mtcars dataset](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html)

## Variables of interest

* **vs**: Engine (0 - V-shaped; 1 = straight)
* **am**: Transmission (0 = automatic, 1 = manual)
* **mpg**: Miles per gallon

```{r}
mtcars <- as.data.frame(mtcars) %>%
  mutate(cyl = factor(cyl),
          vs = factor(vs),
          am = factor(am),
          gear = factor(gear),
          carb = factor(carb))


# First Research Question: 
 # Does engine type influence(!) Transmission Type
 # Null: It does not 
 # Alternative: It does

# Observed difference in proportions 
obs_diff_rq1 <- 
  mtcars %>% 
    select(am, vs) %>% 
    group_by(vs) %>% 
    summarise(prop = mean(am == 1)) %>% 
    summarise(diff_in_props = diff(prop)) %>% 
    pull(diff_in_props)

obs_diff_rq1

# Null distribution: 
null_rq1 <- 
  mtcars %>%
    specify(am ~ vs, success = "1") %>%
    hypothesize(null = "independence") %>%
    generate(reps = 1000, type = "permute") %>%
    calculate(stat = "diff in props", order = c("1", "0"))

# Visualise the Null

null_rq1 %>% 
  ggplot(aes(x = stat)) + 
  geom_histogram() + 
  geom_vline(xintercept = 0) + 
  geom_vline(xintercept = obs_diff_rq1, colour = "red", size = 2)

# P-value (two sided)

null_rq1 %>% 
  summarise(p_val = mean(stat > obs_diff_rq1))

# To answer the RQ in Neyman-Pearson terms, with alpha of 0.05, two-tailed:
# Is the above value either greater than 0.975, or less than 0.025? 



# Second research question: 
 # Do manual transmission vehicles (from the 1970s) have higher MPG?
 # Alternative: They do
 # Null: They don't

# Observed difference in means
obs_diff_rq2 <- 
  mtcars %>% 
    group_by(am) %>% 
    summarise(mean_mpg = mean(mpg)) %>% 
    summarise(diff_in_means = diff(mean_mpg)) %>% 
    pull(diff_in_means)

obs_diff_rq2

null_rq2 <- 
  mtcars %>%
    specify(response = mpg, explanatory = am) %>%
    hypothesize(null = "independence") %>% 
    generate(reps = 1000, type = "permute") %>%
    calculate(stat = "diff in means", order = c("1", "0")) 

# Visualise

null_rq2 %>% 
  ggplot(aes(x = stat)) + 
  geom_histogram(bins = 100) +
  geom_vline(xintercept = 0) + 
  geom_vline(xintercept = obs_diff_rq2, colour = "red", size = 2)

# P-value (one-sided)

null_rq2 %>% 
  summarise(p_val = mean(stat > obs_diff_rq2))

# To answer the RQ in Neyman-Pearson terms, with alpha of 0.05, two-tailed:
# Is the above value either greater than 0.975, or less than 0.025? 

# RQ2 using the t-distribution 

mtcars %>%
  specify(response = mpg, explanatory = am) %>%
  hypothesize(null = "independence") %>% 
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "t", order = c("1", "0")) %>% 
  visualize(method = "both", obs_stat_color = "red", obs_stat = 1.96)


```


This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
